{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62797094",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "62797094",
    "outputId": "10dd0230-63dd-4253-d239-8ceeee6d6a86",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "sys.path.append(\"/content/drive/My Drive/Colab Notebooks/myfs\")\n",
    "\n",
    "import data_lo\n",
    "import fsrcnn\n",
    "\n",
    "def main():\n",
    "    folder = \"/content/drive/My Drive/Colab Notebooks/tens/00000\"\n",
    "    scale = 3\n",
    "    hr_size = (768, 768)\n",
    "    lr_size = (hr_size[0] // scale, hr_size[1] // scale)\n",
    "\n",
    "    lr_images, hr_images = data_lo.load_dataset_from_folder(folder, scale=scale, hr_size=hr_size)\n",
    "    print(f\"Loaded {len(lr_images)} LR-HR image pairs\")\n",
    "\n",
    "    lr_images = np.array(lr_images)\n",
    "    hr_images = np.array(hr_images)\n",
    "\n",
    "    print(f\"LR images shape: {lr_images.shape}\")\n",
    "    print(f\"HR images shape: {hr_images.shape}\")\n",
    "\n",
    "    lr_train, lr_val, hr_train, hr_val = train_test_split(lr_images, hr_images, test_size=0.1, random_state=42)\n",
    "\n",
    "    # model = fsrcnn.fsrcnn_model(input_shape=(lr_size[0], lr_size[1], 3), scale=scale)\n",
    "    # model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    # model.summary()\n",
    "\n",
    "\n",
    "\n",
    "    model_path = \"/content/drive/My Drive/Colab Notebooks/Super_resolution_SRCNN_final.h5\"\n",
    "    model = tf.keras.models.load_model(model_path, compile=False)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    checkpoint_path = \"/content/sr_cnn_model.h5\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n",
    "\n",
    "    history = model.fit(\n",
    "        lr_train,\n",
    "        hr_train,\n",
    "        validation_data=(lr_val, hr_val),\n",
    "        epochs=50,\n",
    "        batch_size=4,\n",
    "        callbacks=[checkpoint]\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    final_model_path = \"/content/drive/My Drive/Colab Notebooks/Super_resolution_SRCNN_final.h5\"\n",
    "    model.save(final_model_path)\n",
    "    print(f\"Model saved to {final_model_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UfPeVKtNq93x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29765,
     "status": "ok",
     "timestamp": 1752818972210,
     "user": {
      "displayName": "Ahtisam Iqbal",
      "userId": "16523060429212571342"
     },
     "user_tz": -300
    },
    "id": "UfPeVKtNq93x",
    "outputId": "2c726f1b-f2df-4e0b-c52f-cb18aac40b63"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MeVN-qWPljcz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 61162,
     "status": "ok",
     "timestamp": 1752820979065,
     "user": {
      "displayName": "Nayab Nasar",
      "userId": "13674303320795123592"
     },
     "user_tz": -300
    },
    "id": "MeVN-qWPljcz",
    "outputId": "c91fc567-b874-4f7e-f94f-bcfd129a8ab6"
   },
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install opencv-python\n",
    "!pip install gdown --quiet\n",
    "!pip install -q PyDrive2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bqK9o7vNlmI8",
   "metadata": {
    "id": "bqK9o7vNlmI8"
   },
   "outputs": [],
   "source": [
    "#to load dataset from public Google Drive folder \n",
    "\n",
    "from pydrive2.auth import GoogleAuth\n",
    "from pydrive2.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "folder_id = \"1taHKxS66YKJNhdhiGcEdM6nnE5W9zBb1\"  # your folder ID\n",
    "file_list = drive.ListFile({'q': f\"'{folder_id}' in parents and trashed=false\"}).GetList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O_f0pKQOlowG",
   "metadata": {
    "id": "O_f0pKQOlowG"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "for file in file_list:\n",
    "    fname = file['title']\n",
    "    print(\"Downloading\", fname)\n",
    "    file.GetContentFile(os.path.join('data', fname))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
